{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time \n",
    "import causaltensor as ct\n",
    "from causaltensor import low_rank_M0_Gamma\n",
    "from causaltensor.matlib import generate_Z\n",
    "from causaltensor.cauest import std_debiased_convex\n",
    "from causaltensor.cauest import projection_T_orthogonal\n",
    "from causaltensor.cauest import DC_PR_with_suggested_rank\n",
    "from causaltensor.cauest import non_convex_algorithm\n",
    "from causaltensor.cauest import DC_PR_auto_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Test\n",
    "\n",
    "Evaluate the standard deviation estimator for the debiased convex algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_experiment_distribution_run_results(n1 = 50, n2 = 50, mean_M = 1, r = 5, num_experiment=1, sigma = 0.1, sigma_d = 0.1, pattern = 'stagger'):\n",
    "    '''\n",
    "        generate (M0, Z) pair:\n",
    "            - M0 has shape (50x50) with mean_M and rank r\n",
    "            - Z is generated in a stagger way, randomly select m1 rows, each row randomly gets treated after column m2\n",
    "            - m1 ~ [1, n1), m2 ~ [n2/5, n2) uniformly\n",
    "\n",
    "        for each (M0, Z) pair:\n",
    "            - compute the score\n",
    "            -   \n",
    "\n",
    "    '''\n",
    "    samples = np.zeros(num_experiment)\n",
    "    t1 = time.time()\n",
    "    for T in range(num_experiment):\n",
    "        if (T % 100 == 0):\n",
    "            print(time.time() - t1)\n",
    "            print('experiment ', T)\n",
    "        #np.random.seed(1)\n",
    "        M0 = low_rank_M0_Gamma(n1 = n1, n2 = n2, r = r, mean_M = mean_M)\n",
    "        ## generating stagger pattern Z\n",
    "        if (pattern == 'stagger'):\n",
    "            m1 = np.random.randint(low=1, high=n1)\n",
    "            m2 = np.random.randint(low=int(n2/2), high=n2)\n",
    "            Z = generate_Z(pattern_tuple=['stagger', (m1, m2)], M0=M0)\n",
    "\n",
    "        if (pattern == 'block'):\n",
    "            m1 = np.random.randint(low=1, high=int(n1/3))\n",
    "            m2 = np.random.randint(low=int(n2/2), high=n2)\n",
    "            Z, treat_units = generate_Z(pattern_tuple=['block', (m1, m2)], M0=M0)\n",
    "\n",
    "        print('***sparsity****', np.sum(Z) / np.size(Z))\n",
    "\n",
    "        tau_star = 1\n",
    "\n",
    "        PTperpZ = projection_T_orthogonal(Z, M0)\n",
    "\n",
    "        # #predict_sigma = sigma / np.sqrt(np.sum(PTperpZ**2))\n",
    "\n",
    "        predict_sigma =  np.sqrt((sigma**2) / np.sum(PTperpZ**2) + (sigma_d**2) * np.sum((PTperpZ**2)*Z) / (np.sum(PTperpZ**2)**2))\n",
    "\n",
    "        # #print(predict_sigma, sigma / np.sqrt(np.sum(PTperpZ**2)))\n",
    "\n",
    "        s = np.linalg.svd(M0, full_matrices=False, compute_uv=False)\n",
    "\n",
    "        def test():\n",
    "            #np.random.seed(T)\n",
    "            E = np.random.normal(loc=0, scale=sigma, size=M0.shape)\n",
    "            delta = np.random.normal(loc = 0, scale = sigma_d, size = M0.shape)\n",
    "            O = M0 + Z * tau_star + E + delta * Z\n",
    "            E_op = np.linalg.norm(E + delta * Z, ord=2)\n",
    "            suggest_l = min(s[r-1]/1.1, E_op*1.1)\n",
    "\n",
    "            #input O/predict_sigma, eliminate precision issue\n",
    "            #results = run_algo(['convex_debias', 'convex'], O, Z, suggest_r = -1, suggest_l = suggest_l, eps = predict_sigma/1000, de_mean_O=False)\n",
    "            \n",
    "            M_debias, tau_debias, M, tau = DC_PR_auto_rank(O, Z)\n",
    "            print(np.linalg.matrix_rank(M), r)\n",
    "\n",
    "            estimated_sigma_level = std_debiased_convex(O, Z, M, tau)\n",
    "\n",
    "            return (tau_debias-tau_star)/estimated_sigma_level\n",
    "\n",
    "            return (tau-tau_star)/predict_sigma\n",
    "\n",
    "        # def KS_test():\n",
    "        #     total = 100\n",
    "        #     tau_samples = np.zeros(total)\n",
    "        #     for i in range(total):\n",
    "        #         tau_samples[i] = test()\n",
    "        #     KS_statistic, p_value = scipy.stats.ks_1samp(tau_samples, scipy.stats.norm.cdf)\n",
    "        #     print(KS_statistic, p_value)\n",
    "        #     return KS_statistic\n",
    "\n",
    "        samples[T] = test()\n",
    "        print('experiment {}, time elapses {}, tau error {}'.format(T, time.time() - t1, samples[T]))\n",
    "        #print(samples[T], predict_sigma)\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up\n",
    "n1 = 100\n",
    "n2 = 100\n",
    "mean_M = 10\n",
    "r = 2\n",
    "sigma = 1\n",
    "sigma_d = 1\n",
    "\n",
    "samples = synthetic_experiment_distribution_run_results(n1 = n1, n2 = n2, mean_M = mean_M, r = r, sigma = sigma, sigma_d = sigma, num_experiment = 100, pattern = 'block')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Plot\n",
    "check whether the distribution is like Gaussian or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "\n",
    "def synthetic_experiment_distribution_plot_distribution_results(samples):\n",
    "    hist, bined = np.histogram(samples, bins = 30, density=True)\n",
    "    plt.plot((bined[:-1]/2+bined[1:]/2), hist)\n",
    "    pos_guassian = np.linspace(min(samples), max(samples), 1000)\n",
    "    pdf_guassian = norm.pdf(pos_guassian, loc=0, scale=1)\n",
    "    plt.plot(pos_guassian, pdf_guassian)\n",
    "    plt.show()\n",
    "\n",
    "    print(np.mean(samples), np.std(samples))\n",
    "\n",
    "    g = sns.displot(data=samples, kind='hist', stat='density')\n",
    "    g.set(xlim=(-4, 4))\n",
    "    g.set(ylim=(0.0, 0.45))\n",
    "    plt.plot(pos_guassian, pdf_guassian, label=r'$N(0, 1)$', color='r')\n",
    "    plt.legend(fontsize = 17)\n",
    "    plt.ylabel('Density', fontsize = 18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    x = scipy.stats.norm.rvs(loc=0, size=100000)\n",
    "    sns.ecdfplot(data=x)\n",
    "    plt.show()\n",
    "\n",
    "synthetic_experiment_distribution_plot_distribution_results(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4 (default, Aug 13 2019, 15:17:50) \n[Clang 4.0.1 (tags/RELEASE_401/final)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
