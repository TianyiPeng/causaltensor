{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8453a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "\n",
    "\n",
    "def create_y_dataframe(df, index_col, column_col, value_col):\n",
    "    \"\"\"\n",
    "    Create Y dataframe (entity x time matrix) from long-form data.\n",
    "    \n",
    "    Args:\n",
    "        df: Long-form dataframe\n",
    "        index_col: Column name for entities/rows\n",
    "        column_col: Column name for time periods/columns\n",
    "        value_col: Column name for values\n",
    "    \n",
    "    Returns:\n",
    "        Y_df: Wide-form dataframe with entities as index and time as columns\n",
    "    \"\"\"\n",
    "    df[column_col] = df[column_col].astype(int)\n",
    "\n",
    "    Y_df = df.pivot(index=index_col, columns=column_col, values=value_col)\n",
    "    return Y_df\n",
    "\n",
    "\n",
    "def create_z_dataframe(Y_df, treated_entity, treatment_start_year):\n",
    "    \"\"\"\n",
    "    Create Z dataframe (treatment indicator matrix).\n",
    "    \n",
    "    Args:\n",
    "        Y_df: Entity x time matrix\n",
    "        treated_entity: Name of the treated entity\n",
    "        treatment_start_year: Year when treatment starts\n",
    "    \n",
    "    Returns:\n",
    "        Z_df: Treatment indicator matrix (1 for treated entity after treatment, 0 otherwise)\n",
    "    \"\"\"\n",
    "    Z_df = pd.DataFrame(0, index=Y_df.index, columns=Y_df.columns)\n",
    "    treated_mask = Z_df.index == treated_entity\n",
    "    post_treatment_mask = Z_df.columns >= treatment_start_year\n",
    "    Z_df.loc[treated_mask, post_treatment_mask] = 1\n",
    "    return Z_df\n",
    "\n",
    "\n",
    "def create_x_dataframe(df, Y_df, index_col, time_col, covariate_cols, avg_start_year, avg_end_year, \n",
    "                       additional_cols=None):\n",
    "    \"\"\"\n",
    "    Create X dataframe (covariates matrix) by averaging over pre-treatment period.\n",
    "    \n",
    "    Args:\n",
    "        df: Long-form dataframe\n",
    "        Y_df: Entity x time matrix\n",
    "        index_col: Column name for entities\n",
    "        time_col: Column name for time periods\n",
    "        covariate_cols: List of covariate columns to average\n",
    "        avg_start_year: Start year for averaging period\n",
    "        avg_end_year: End year for averaging period\n",
    "        additional_cols: Dict mapping new column names to years to add from Y_df\n",
    "                        e.g., {'Smoking 1988': 1988, 'Smoking 1980': 1980}\n",
    "    \n",
    "    Returns:\n",
    "        X_df: Covariates matrix with entities as rows\n",
    "    \"\"\"\n",
    "    # Filter to averaging period\n",
    "    mask = (df[time_col] >= avg_start_year) & (df[time_col] <= avg_end_year)\n",
    "    \n",
    "    # Average covariates over period\n",
    "    X_df = (\n",
    "        df.loc[mask, [index_col] + covariate_cols]\n",
    "          .groupby(index_col, as_index=False)\n",
    "          .mean()\n",
    "    )\n",
    "    \n",
    "    # Add additional columns from Y_df if specified\n",
    "    if additional_cols is not None:\n",
    "        for col_name, year in additional_cols.items():\n",
    "            if year in Y_df.columns:\n",
    "                X_df[col_name] = Y_df[year].values\n",
    "    \n",
    "    return X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7345809",
   "metadata": {},
   "source": [
    "### Smoking Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c779c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the smoking.rda data (if not already loaded)\n",
    "result = pyreadr.read_r('../src/causaltensor/datasets/raw/smoking.rda')\n",
    "df = list(result.values())[0]\n",
    "\n",
    "# State mapping from documentation\n",
    "state_mapping = {\n",
    "    1: 'Alabama', 2: 'Arkansas', 3: 'California', 4: 'Colorado',\n",
    "    5: 'Connecticut', 6: 'Delaware', 7: 'Georgia', 8: 'Idaho',\n",
    "    9: 'Illinois', 10: 'Indiana', 11: 'Iowa', 12: 'Kansas',\n",
    "    13: 'Kentucky', 14: 'Louisiana', 15: 'Maine', 16: 'Minnesota',\n",
    "    17: 'Mississippi', 18: 'Missouri', 19: 'Montana', 20: 'Nebraska',\n",
    "    21: 'Nevada', 22: 'New Hampshire', 23: 'New Mexico', 24: 'North Carolina',\n",
    "    25: 'North Dakota', 26: 'Ohio', 27: 'Oklahoma', 28: 'Pennsylvania',\n",
    "    29: 'Rhode Island', 30: 'South Carolina', 31: 'South Dakota', 32: 'Tennessee',\n",
    "    33: 'Texas', 34: 'Utah', 35: 'Vermont', 36: 'Virginia',\n",
    "    37: 'West Virginia', 38: 'Wisconsin', 39: 'Wyoming'\n",
    "}\n",
    "df[\"state\"] = df[\"state\"].map(state_mapping)\n",
    "\n",
    "\n",
    "# Create Y_df, Z_df, and X_df using helper functions\n",
    "Y_df = create_y_dataframe(df, index_col=\"state\", column_col=\"year\", value_col=\"cigsale\")\n",
    "Y = Y_df.to_numpy()\n",
    "\n",
    "# Create Z matrix: 1 for California after 1988, 0 otherwise\n",
    "Z_df = create_z_dataframe(Y_df, treated_entity='California', treatment_start_year=1988)\n",
    "\n",
    "# Create X dataframe\n",
    "cols_to_avg = [col for col in df.columns if col not in ['state', 'year', 'cigsale']]\n",
    "X_df = create_x_dataframe(\n",
    "    df, Y_df, \n",
    "    index_col='state', \n",
    "    time_col='year',\n",
    "    covariate_cols=cols_to_avg,\n",
    "    avg_start_year=1980, \n",
    "    avg_end_year=1988,\n",
    "    additional_cols={'Smoking 1988': 1988, 'Smoking 1980': 1980, 'Smoking 1975': 1975}\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6743cf2",
   "metadata": {},
   "source": [
    "### Basque Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42300a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the basque.rda data \n",
    "result = pyreadr.read_r('../src/causaltensor/datasets/raw/basque.rda')\n",
    "df = list(result.values())[0]\n",
    "\n",
    "\n",
    "# Create Y_df, Z_df, and X_df using helper functions\n",
    "Y_df = create_y_dataframe(df, index_col=\"regionname\", column_col=\"year\", value_col=\"gdpcap\")\n",
    "\n",
    "Z_df = create_z_dataframe(Y_df, treated_entity='Basque Country (Pais Vasco)', treatment_start_year=1975)\n",
    "\n",
    "cols_to_avg = ['invest', 'secagriculture',\n",
    "       'secenergy', 'secindustry', 'secconstruction', 'secservicesventa',\n",
    "       'secservicesnonventa', 'schoolillit', 'schoolprim', 'schoolmed',\n",
    "       'schoolhigh', 'schoolposthigh', 'popdens']\n",
    "\n",
    "X_df = create_x_dataframe(\n",
    "    df, Y_df,\n",
    "    index_col='regionname',\n",
    "    time_col='year',\n",
    "    covariate_cols=cols_to_avg,\n",
    "    avg_start_year=1964,\n",
    "    avg_end_year=1969,\n",
    "    additional_cols={'gdpcap1960': 1960, 'gdpcap1965': 1965, 'gdpcap1970': 1970}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdfb66e",
   "metadata": {},
   "source": [
    "### German Reunification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fe7371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../src/causaltensor/datasets/raw/german_reunification.csv')\n",
    "\n",
    "\n",
    "# Create Y_df, Z_df, and X_df using helper functions\n",
    "Y_df = create_y_dataframe(df, index_col=\"country\", column_col=\"year\", value_col=\"gdp\")\n",
    "Y_df\n",
    "\n",
    "Z_df = create_z_dataframe(Y_df, treated_entity='West Germany', treatment_start_year=1990)\n",
    "\n",
    "cols_to_avg = ['infrate', 'trade', 'schooling', 'industry']\n",
    "\n",
    "X_df = create_x_dataframe(\n",
    "    df, Y_df,\n",
    "    index_col='country',\n",
    "    time_col='year',\n",
    "    covariate_cols=cols_to_avg,\n",
    "    avg_start_year=1980,\n",
    "    avg_end_year=1985,\n",
    "    additional_cols={'gdp1960': 1960, 'gdp1970': 1970, 'gdp1980': 1980, 'gdp1985': 1985}\n",
    ")\n",
    "\n",
    "# Add investment columns (these are pre-existing in the original data)\n",
    "X_df['invest60'] = df[~df['invest60'].isna()]['invest60'].values\n",
    "X_df['invest70'] = df[~df['invest70'].isna()]['invest70'].values\n",
    "X_df['invest80'] = df[~df['invest80'].isna()]['invest80'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b4bb9",
   "metadata": {},
   "source": [
    "### Texas Prison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pyreadr.read_r('../src/causaltensor/datasets/raw/texas.rda')\n",
    "df = list(result.values())[0]\n",
    "\n",
    "\n",
    "fips_map = {\n",
    "    1: \"Alabama\", 2: \"Alaska\", 4: \"Arizona\", 5: \"Arkansas\", 6: \"California\",\n",
    "    8: \"Colorado\", 9: \"Connecticut\", 10: \"Delaware\", 11: \"District of Columbia\",\n",
    "    12: \"Florida\", 13: \"Georgia\", 15: \"Hawaii\", 16: \"Idaho\", 17: \"Illinois\",\n",
    "    18: \"Indiana\", 19: \"Iowa\", 20: \"Kansas\", 21: \"Kentucky\", 22: \"Louisiana\",\n",
    "    23: \"Maine\", 24: \"Maryland\", 25: \"Massachusetts\", 26: \"Michigan\",\n",
    "    27: \"Minnesota\", 28: \"Mississippi\", 29: \"Missouri\", 30: \"Montana\",\n",
    "    31: \"Nebraska\", 32: \"Nevada\", 33: \"New Hampshire\", 34: \"New Jersey\",\n",
    "    35: \"New Mexico\", 36: \"New York\", 37: \"North Carolina\", 38: \"North Dakota\",\n",
    "    39: \"Ohio\", 40: \"Oklahoma\", 41: \"Oregon\", 42: \"Pennsylvania\", 44: \"Rhode Island\",\n",
    "    45: \"South Carolina\", 46: \"South Dakota\", 47: \"Tennessee\", 48: \"Texas\",\n",
    "    49: \"Utah\", 50: \"Vermont\", 51: \"Virginia\", 53: \"Washington\", 54: \"West Virginia\",\n",
    "    55: \"Wisconsin\", 56: \"Wyoming\"\n",
    "}\n",
    "\n",
    "df[\"state\"] = df[\"statefip\"].map(fips_map)\n",
    "\n",
    "# Create Y_df, Z_df, and X_df using helper functions\n",
    "Y_df = create_y_dataframe(df, index_col=\"state\", column_col=\"year\", value_col=\"bmprate\")\n",
    "\n",
    "Z_df = create_z_dataframe(Y_df, treated_entity='Texas', treatment_start_year=1993)\n",
    "\n",
    "cols_to_avg = [\"income\", \"ur\", \"poverty\", \"black\", \"perc1519\",\n",
    "  \"aidscapita\", \"crack\", \"alcohol\", \"parole\",\n",
    "  \"probation\", \"capacity_operational\"]\n",
    "\n",
    "X_df = create_x_dataframe(\n",
    "    df, Y_df,\n",
    "    index_col='state',\n",
    "    time_col='year',\n",
    "    covariate_cols=cols_to_avg,\n",
    "    avg_start_year=1985,\n",
    "    avg_end_year=1993,\n",
    "    additional_cols={'bmprate1985': 1985, 'bmprate1990': 1990, 'bmprate1993': 1993}\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c069ce8",
   "metadata": {},
   "source": [
    "### PWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d415d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countrycode</th>\n",
       "      <th>country</th>\n",
       "      <th>currency_unit</th>\n",
       "      <th>year</th>\n",
       "      <th>rgdpe</th>\n",
       "      <th>rgdpo</th>\n",
       "      <th>pop</th>\n",
       "      <th>emp</th>\n",
       "      <th>avh</th>\n",
       "      <th>hc</th>\n",
       "      <th>...</th>\n",
       "      <th>csh_x</th>\n",
       "      <th>csh_m</th>\n",
       "      <th>csh_r</th>\n",
       "      <th>pl_c</th>\n",
       "      <th>pl_i</th>\n",
       "      <th>pl_g</th>\n",
       "      <th>pl_x</th>\n",
       "      <th>pl_m</th>\n",
       "      <th>pl_k</th>\n",
       "      <th>openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>Aruban Guilder</td>\n",
       "      <td>1950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABW</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>Aruban Guilder</td>\n",
       "      <td>1951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABW</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>Aruban Guilder</td>\n",
       "      <td>1952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABW</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>Aruban Guilder</td>\n",
       "      <td>1953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABW</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>Aruban Guilder</td>\n",
       "      <td>1954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11825</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2010</td>\n",
       "      <td>20652.718750</td>\n",
       "      <td>21053.855469</td>\n",
       "      <td>13.973897</td>\n",
       "      <td>6.298438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.372605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214657</td>\n",
       "      <td>-0.454497</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>0.447170</td>\n",
       "      <td>0.543100</td>\n",
       "      <td>0.411316</td>\n",
       "      <td>0.701797</td>\n",
       "      <td>0.606324</td>\n",
       "      <td>1.015145</td>\n",
       "      <td>-0.239839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11826</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2011</td>\n",
       "      <td>20720.435547</td>\n",
       "      <td>21592.298828</td>\n",
       "      <td>14.255592</td>\n",
       "      <td>6.518841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.415823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219809</td>\n",
       "      <td>-0.625170</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>0.531029</td>\n",
       "      <td>0.606065</td>\n",
       "      <td>0.440252</td>\n",
       "      <td>0.739989</td>\n",
       "      <td>0.637035</td>\n",
       "      <td>0.470333</td>\n",
       "      <td>-0.405361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11827</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2012</td>\n",
       "      <td>23708.654297</td>\n",
       "      <td>24360.527344</td>\n",
       "      <td>14.565482</td>\n",
       "      <td>6.248271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.459828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225631</td>\n",
       "      <td>-0.479897</td>\n",
       "      <td>-0.076998</td>\n",
       "      <td>0.474047</td>\n",
       "      <td>1.363167</td>\n",
       "      <td>0.458315</td>\n",
       "      <td>0.712036</td>\n",
       "      <td>0.634858</td>\n",
       "      <td>0.608320</td>\n",
       "      <td>-0.254266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11828</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2013</td>\n",
       "      <td>27011.988281</td>\n",
       "      <td>28157.886719</td>\n",
       "      <td>14.898092</td>\n",
       "      <td>6.287056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.504635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174443</td>\n",
       "      <td>-0.436145</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.498061</td>\n",
       "      <td>0.575870</td>\n",
       "      <td>0.465031</td>\n",
       "      <td>0.717884</td>\n",
       "      <td>0.630712</td>\n",
       "      <td>0.414526</td>\n",
       "      <td>-0.261702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11829</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2014</td>\n",
       "      <td>28495.554688</td>\n",
       "      <td>29149.708984</td>\n",
       "      <td>15.245855</td>\n",
       "      <td>6.499974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.550258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147346</td>\n",
       "      <td>-0.349806</td>\n",
       "      <td>-0.020068</td>\n",
       "      <td>0.528013</td>\n",
       "      <td>0.550110</td>\n",
       "      <td>0.464699</td>\n",
       "      <td>0.716963</td>\n",
       "      <td>0.628869</td>\n",
       "      <td>0.386039</td>\n",
       "      <td>-0.202460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11830 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      countrycode   country   currency_unit  year         rgdpe         rgdpo  \\\n",
       "0             ABW     Aruba  Aruban Guilder  1950           NaN           NaN   \n",
       "1             ABW     Aruba  Aruban Guilder  1951           NaN           NaN   \n",
       "2             ABW     Aruba  Aruban Guilder  1952           NaN           NaN   \n",
       "3             ABW     Aruba  Aruban Guilder  1953           NaN           NaN   \n",
       "4             ABW     Aruba  Aruban Guilder  1954           NaN           NaN   \n",
       "...           ...       ...             ...   ...           ...           ...   \n",
       "11825         ZWE  Zimbabwe       US Dollar  2010  20652.718750  21053.855469   \n",
       "11826         ZWE  Zimbabwe       US Dollar  2011  20720.435547  21592.298828   \n",
       "11827         ZWE  Zimbabwe       US Dollar  2012  23708.654297  24360.527344   \n",
       "11828         ZWE  Zimbabwe       US Dollar  2013  27011.988281  28157.886719   \n",
       "11829         ZWE  Zimbabwe       US Dollar  2014  28495.554688  29149.708984   \n",
       "\n",
       "             pop       emp  avh        hc  ...     csh_x     csh_m     csh_r  \\\n",
       "0            NaN       NaN  NaN       NaN  ...       NaN       NaN       NaN   \n",
       "1            NaN       NaN  NaN       NaN  ...       NaN       NaN       NaN   \n",
       "2            NaN       NaN  NaN       NaN  ...       NaN       NaN       NaN   \n",
       "3            NaN       NaN  NaN       NaN  ...       NaN       NaN       NaN   \n",
       "4            NaN       NaN  NaN       NaN  ...       NaN       NaN       NaN   \n",
       "...          ...       ...  ...       ...  ...       ...       ...       ...   \n",
       "11825  13.973897  6.298438  NaN  2.372605  ...  0.214657 -0.454497  0.014462   \n",
       "11826  14.255592  6.518841  NaN  2.415823  ...  0.219809 -0.625170  0.004390   \n",
       "11827  14.565482  6.248271  NaN  2.459828  ...  0.225631 -0.479897 -0.076998   \n",
       "11828  14.898092  6.287056  NaN  2.504635  ...  0.174443 -0.436145 -0.000005   \n",
       "11829  15.245855  6.499974  NaN  2.550258  ...  0.147346 -0.349806 -0.020068   \n",
       "\n",
       "           pl_c      pl_i      pl_g      pl_x      pl_m      pl_k  openness  \n",
       "0           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "1           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "3           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "11825  0.447170  0.543100  0.411316  0.701797  0.606324  1.015145 -0.239839  \n",
       "11826  0.531029  0.606065  0.440252  0.739989  0.637035  0.470333 -0.405361  \n",
       "11827  0.474047  1.363167  0.458315  0.712036  0.634858  0.608320 -0.254266  \n",
       "11828  0.498061  0.575870  0.465031  0.717884  0.630712  0.414526 -0.261702  \n",
       "11829  0.528013  0.550110  0.464699  0.716963  0.628869  0.386039 -0.202460  \n",
       "\n",
       "[11830 rows x 48 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../src/causaltensor/datasets/raw/PWT.csv')\n",
    "df['openness'] = df['csh_x'] + df['csh_m']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ecc54",
   "metadata": {},
   "source": [
    "##### Effect of Spain joining EU in 1986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a5408b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arushi Jain\\AppData\\Local\\Temp\\ipykernel_29340\\3494488595.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_col] = df[column_col].astype(int)\n"
     ]
    }
   ],
   "source": [
    "df1 = df[(df['year'] >= 1970) & (df['year'] <= 2000)]\n",
    "Y_df = create_y_dataframe(df1, index_col=\"country\", column_col=\"year\", value_col=\"rgdpe\")\n",
    "\n",
    "Z_df = create_z_dataframe(Y_df, treated_entity='Spain', treatment_start_year=1986)\n",
    "\n",
    "cols_to_avg = [\"hc\",\"csh_i\",\"csh_c\",\"csh_g\",\"openness\",\"pl_gdpo\", \"pop\"]\n",
    "\n",
    "X_df = create_x_dataframe(\n",
    "    df1, Y_df,\n",
    "    index_col='country',\n",
    "    time_col='year',\n",
    "    covariate_cols=cols_to_avg,\n",
    "    avg_start_year=1970,\n",
    "    avg_end_year=1980,\n",
    "    additional_cols={'rgdpe1970': 1970, 'rgdpe1980': 1980, 'rgdpe1985': 1985}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a89736b",
   "metadata": {},
   "source": [
    "##### Effect of Trade Liberalization in Chile 1976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80749e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arushi Jain\\AppData\\Local\\Temp\\ipykernel_29340\\3494488595.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_col] = df[column_col].astype(int)\n"
     ]
    }
   ],
   "source": [
    "df1 = df[(df['year'] >= 1960) & (df['year'] <= 1995)]\n",
    "\n",
    "\n",
    "Y_df = create_y_dataframe(df1, index_col=\"country\", column_col=\"year\", value_col=\"rgdpo\")\n",
    "\n",
    "\n",
    "Z_df = create_z_dataframe(Y_df, treated_entity='Chile', treatment_start_year=1976)\n",
    "\n",
    "cols_to_avg = [\"hc\",\"csh_i\",\"csh_c\",\"csh_g\",\"openness\",\"pl_gdpo\", \"rkna\"]\n",
    "\n",
    "X_df = create_x_dataframe(\n",
    "    df1, Y_df,\n",
    "    index_col='country',\n",
    "    time_col='year',\n",
    "    covariate_cols=cols_to_avg,\n",
    "    avg_start_year=1970,\n",
    "    avg_end_year=1975,\n",
    "    additional_cols={'rgdpo1970': 1970, 'rgdpo1975': 1975}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19584649",
   "metadata": {},
   "source": [
    "##### Effect of Democratization in Republic of Korea in 1988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0e5a1ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arushi Jain\\AppData\\Local\\Temp\\ipykernel_29340\\3494488595.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_col] = df[column_col].astype(int)\n"
     ]
    }
   ],
   "source": [
    "df1 = df[(df['year'] >= 1970) & (df['year'] <= 2000)]\n",
    "\n",
    "\n",
    "Y_df = create_y_dataframe(df1, index_col=\"country\", column_col=\"year\", value_col=\"rgdpe\")\n",
    "\n",
    "\n",
    "Z_df = create_z_dataframe(Y_df, treated_entity='Republic of Korea', treatment_start_year=1988)\n",
    "\n",
    "cols_to_avg = [\"hc\",\"csh_i\",\"csh_g\",\"openness\",\"ctfp\"]\n",
    "\n",
    "X_df = create_x_dataframe(\n",
    "    df1, Y_df,\n",
    "    index_col='country',\n",
    "    time_col='year',\n",
    "    covariate_cols=cols_to_avg,\n",
    "    avg_start_year=1980,\n",
    "    avg_end_year=1987,\n",
    "    additional_cols={'rgdpe1980': 1980, 'rgdpe1988': 1985}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd19da",
   "metadata": {},
   "source": [
    "##### Resource Discovery: Norway 1971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8384cb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arushi Jain\\AppData\\Local\\Temp\\ipykernel_29340\\3494488595.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_col] = df[column_col].astype(int)\n"
     ]
    }
   ],
   "source": [
    "df1 = df[(df['year'] >= 1960) & (df['year'] <= 1980)]\n",
    "\n",
    "\n",
    "Y_df = create_y_dataframe(df1, index_col=\"country\", column_col=\"year\", value_col=\"rgdpe\")\n",
    "\n",
    "\n",
    "Z_df = create_z_dataframe(Y_df, treated_entity='Norway', treatment_start_year=1971)\n",
    "\n",
    "cols_to_avg = [\"hc\",\"csh_i\",\"csh_g\",\"openness\",\"rkna\",\"pl_gdpo\"]\n",
    "\n",
    "X_df = create_x_dataframe(\n",
    "    df1, Y_df,\n",
    "    index_col='country',\n",
    "    time_col='year',\n",
    "    covariate_cols=cols_to_avg,\n",
    "    avg_start_year=1960,\n",
    "    avg_end_year=1970,\n",
    "    additional_cols={'rgdpe1965': 1965, 'rgdpe1970': 1970}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a3ed0",
   "metadata": {},
   "source": [
    "### Retailrocket Recsys Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f702fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../src/causaltensor/datasets/raw/retailrocket.csv', engine=\"python\", sep=None)\n",
    "df = df[df['event'] == 'view']\n",
    "df['date'] = pd.to_datetime(df['timestamp'], unit='ms').dt.date\n",
    "df['day'] = pd.to_numeric(df['date'].astype('category').cat.codes)\n",
    "pop_items = df.groupby('itemid')['day'].nunique() > 20\n",
    "items_to_keep = pop_items[pop_items].index\n",
    "df = df[df['itemid'].isin(items_to_keep)]\n",
    "df = df[['visitorid', 'itemid', 'day']]\n",
    "df.to_csv('../src/causaltensor/datasets/raw/retailrocket_filtered.csv', index=False)\n",
    "df = df.groupby(['itemid', 'day']).size().reset_index(name='count')\n",
    "Y_df = create_y_dataframe(df, index_col=\"itemid\", column_col=\"day\", value_col=\"count\").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a484ddb3",
   "metadata": {},
   "source": [
    "### Dunnhumby Recsys Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d940c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../src/causaltensor/datasets/raw/dunnhumby.csv', engine=\"python\", sep=None)\n",
    "df = df[df['STORE_ID'] == 367] # filter to most popular store\n",
    "df = df.groupby(['PRODUCT_ID', 'DAY'])[['SALES_VALUE', 'RETAIL_DISC']].sum().reset_index()\n",
    "df['PROMO'] = (df['RETAIL_DISC'] < 0).astype(int) # Use retail discount as treatment proxy\n",
    "df.to_csv('../src/causaltensor/datasets/raw/dunnhumby_filtered.csv', index=False)\n",
    "Y_df = create_y_dataframe(df, index_col=\"PRODUCT_ID\", column_col=\"DAY\", value_col=\"SALES_VALUE\").fillna(0)\n",
    "Z_df = create_y_dataframe(df, index_col=\"PRODUCT_ID\", column_col=\"DAY\", value_col=\"PROMO\").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04897490",
   "metadata": {},
   "source": [
    "### Truus Recsys Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deba728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>day</th>\n",
       "      <th>734473</th>\n",
       "      <th>734474</th>\n",
       "      <th>734475</th>\n",
       "      <th>734476</th>\n",
       "      <th>734477</th>\n",
       "      <th>734479</th>\n",
       "      <th>734481</th>\n",
       "      <th>734482</th>\n",
       "      <th>734483</th>\n",
       "      <th>734484</th>\n",
       "      <th>...</th>\n",
       "      <th>734938</th>\n",
       "      <th>734939</th>\n",
       "      <th>734940</th>\n",
       "      <th>734941</th>\n",
       "      <th>734942</th>\n",
       "      <th>734943</th>\n",
       "      <th>734944</th>\n",
       "      <th>734945</th>\n",
       "      <th>734946</th>\n",
       "      <th>734947</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sku_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 447 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "day     734473  734474  734475  734476  734477  734479  734481  734482  \\\n",
       "sku_id                                                                   \n",
       "1          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "5          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "390        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "391        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "392        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "393        0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "394        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "day     734483  734484  ...  734938  734939  734940  734941  734942  734943  \\\n",
       "sku_id                  ...                                                   \n",
       "1          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3          0.0     0.0  ...     0.0     2.0     0.0     1.0     0.0     1.0   \n",
       "4          0.0     0.0  ...     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "5          0.0     0.0  ...     1.0     0.0     1.0     1.0     1.0     1.0   \n",
       "...        ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "390        0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "391        0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "392        0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "393        0.0     0.0  ...     0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "394        0.0     0.0  ...     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "day     734944  734945  734946  734947  \n",
       "sku_id                                  \n",
       "1          0.0     0.0     0.0     0.0  \n",
       "2          0.0     0.0     0.0     0.0  \n",
       "3          1.0     1.0     1.0     1.0  \n",
       "4          0.0     0.0     0.0     0.0  \n",
       "5          3.0     3.0     0.0     0.0  \n",
       "...        ...     ...     ...     ...  \n",
       "390        2.0     0.0     0.0     0.0  \n",
       "391        0.0     0.0     0.0     0.0  \n",
       "392        0.0     0.0     1.0     1.0  \n",
       "393        0.0     0.0     0.0     0.0  \n",
       "394        0.0     0.0     1.0     0.0  \n",
       "\n",
       "[394 rows x 447 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../src/causaltensor/datasets/raw/truus.csv', engine=\"python\", sep=None)\n",
    "df = df.groupby(['sku_id', 'day']).size().reset_index(name='count')\n",
    "Y_df = create_y_dataframe(df, index_col=\"sku_id\", column_col=\"day\", value_col=\"count\").fillna(0)\n",
    "Y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b12bd3",
   "metadata": {},
   "source": [
    "### Movielens Recsys Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c0647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../src/causaltensor/datasets/raw/movielens.data', sep='\\t', header=None, \n",
    "                 names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "df['date'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "df['day'] = pd.to_numeric(df['date'].astype('category').cat.codes)\n",
    "df = df.groupby(['movie_id', 'day']).size().reset_index(name='count')\n",
    "Y_df = create_y_dataframe(df, index_col=\"movie_id\", column_col=\"day\", value_col=\"count\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd6427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
